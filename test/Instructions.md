### **1. Installation des dÃ©pendances**

```bash
# Pour tester les modÃ¨les Transformers
pip install transformers torch accelerate bitsandbytes

# Pour tester GPT (optionnel)
pip install openai

# DÃ©pendances de base
pip install numpy pandas matplotlib
```

### **2. Utilisation du script**

```bash
# Test d'un modÃ¨le spÃ©cifique sur tous les cas
python test_reasoning_models.py --model pattern-based

# Test sur un cas spÃ©cifique  
python test_reasoning_models.py --model phi-3.5 --test-id 1

# Sauvegarder le rapport
python test_reasoning_models.py --model qwen2.5 --output rapport_qwen.json
```

### **3. Exemples de rÃ©sultats attendus**

```
ğŸ§ª Test du modÃ¨le: pattern-based
âœ… ModÃ¨le pattern-based chargÃ©

ğŸ“„ Test 1: laptop_simple
  â“ Question 1: What is the product name and model?...
    ğŸ“Š Score: 0.85 (0.01s)
  â“ Question 2: What are the power consumption values?...
    ğŸ“Š Score: 0.95 (0.01s)

====================================================
ğŸ“Š RAPPORT FINAL
====================================================
ModÃ¨le: pattern-based
Tests rÃ©ussis: 18/20
Score moyen: 0.73
Temps moyen: 0.02s

ğŸ“ˆ Scores par type de test:
  laptop_simple: 0.90
  monitor_technical: 0.78
  server_complex: 0.65
  ...
```

## ğŸ¯ **Types de tests dans le dataset**

### **ğŸŸ¢ Tests simples (scores attendus Ã©levÃ©s)**
- **Test 1** : Laptop HP (donnÃ©es basiques)
- **Test 6** : Tablet Samsung (unitÃ©s mixtes)

### **ğŸŸ¡ Tests intermÃ©diaires** 
- **Test 2** : Monitor Dell (formats variÃ©s)
- **Test 5** : Printer Canon (tableaux)
- **Test 9** : TV LG (comparaisons multiples)

### **ğŸ”´ Tests difficiles**
- **Test 3** : Server Microsoft (analyse complexe)
- **Test 4** : iPhone (OCR bruitÃ© Ã  corriger)
- **Test 8** : Workstation Dell (lifecycle dÃ©taillÃ©)
- **Test 10** : PlayStation (analyse complÃ¨te)

### **ğŸ² Test baseline**
- **Test 7** : Router Netgear (donnÃ©es manquantes)

## ğŸ’¡ **Comment interprÃ©ter les rÃ©sultats**

### **Scores de rÃ©fÃ©rence attendus :**

| ModÃ¨le | Score moyen | Temps | Commentaire |
|--------|-------------|-------|-------------|
| Pattern-based | 0.60-0.75 | <0.1s | âš¡ Rapide mais limitÃ© |
| Phi-3.5 Mini | 0.80-0.90 | 1-3s | ğŸ¯ Optimal pour ton cas |
| Qwen2.5-3B | 0.75-0.85 | 0.5-2s | âš¡ Bon compromis vitesse/qualitÃ© |
| GPT-3.5 | 0.85-0.92 | 0.5-1s | ğŸ’° Excellent mais payant |

### **CritÃ¨res de dÃ©cision :**

- **Score > 0.8** : Excellent pour ton stage
- **Temps < 2s** : Acceptable pour usage interactif  
- **Tests difficiles > 0.7** : Robuste pour docs complexes

## ğŸ”¬ **Personnalisation pour ton domaine**

Tu peux facilement ajouter tes propres cas de test :

```python
# Ajouter dans le dataset
{
    "id": 11,
    "type": "ton_cas_specifique", 
    "text": "Contenu d'un vrai doc de constructeur...",
    "questions": [
        {
            "question": "Extraire la consommation en mode Ã©conomique",
            "expected_answer": {"eco_mode": {"value": 12, "unit": "W"}}
        }
    ]
}
```

## ğŸª **Tests que tu peux faire dÃ¨s maintenant**

1. **Test baseline** : Lance le pattern-based pour voir les scores de rÃ©fÃ©rence
2. **Test avec tes docs** : Remplace le texte par du vrai contenu OCR de ton projet
3. **Comparaison modÃ¨les** : Teste 2-3 modÃ¨les diffÃ©rents sur le mÃªme cas
4. **Ã‰valuation temps** : Mesure les performances sur ton hardware